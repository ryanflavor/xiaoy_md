# Test Design: Story 1.1 - Project Repository and Tooling Setup

Date: 2025-09-03  
Designer: Quinn (Test Architect)  
Mode: Linux MVP Focus - Simplified Testing Strategy

## Test Strategy Overview

- **Total test scenarios**: 28 (reduced from 42)
- **Unit tests**: 12 (43%)
- **Integration tests**: 12 (43%)
- **E2E tests**: 4 (14%)
- **Priority distribution**: P0: 15, P1: 10, P2: 3, P3: 0

## Critical Focus Areas (Linux MVP)

### 1. Linux Environment Optimization
**Objective**: Ensure consistent Linux deployment environment

### 2. Architecture Validation Testing  
**Objective**: Prevent hexagonal architecture violations from day one

### 3. Container-Ready Setup
**Objective**: Guarantee Docker deployment compatibility

## Test Scenarios by Acceptance Criteria

### AC1: Git Repository Initialized

#### Core Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-001 | Unit | P0 | **Given** clean directory **When** git init **Then** .git folder created | Core functionality |
| 1.1-UNIT-002 | Unit | P0 | **Given** .gitignore template **When** parsed **Then** Python patterns present | Validation logic |
| 1.1-INT-001 | Integration | P0 | **Given** initialized repo **When** first commit **Then** main branch active | Multi-component |

#### Linux Environment Tests

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-INT-002 | Integration | P0 | **Given** Linux **When** git init **Then** permissions preserved correctly | Linux integrity |
| 1.1-INT-003 | Integration | P0 | **Given** Ubuntu/Debian **When** setup **Then** all dependencies available | Distro support |
| 1.1-E2E-001 | E2E | P0 | **Given** fresh Linux server **When** setup **Then** environment ready < 15min | Quick setup |

### AC2: pyproject.toml Configured for uv

#### Core Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-003 | Unit | P0 | **Given** pyproject.toml **When** parsed **Then** valid TOML structure | Pure validation |
| 1.1-UNIT-004 | Unit | P0 | **Given** Python version **When** specified **Then** exactly 3.13 | Requirement check |
| 1.1-INT-005 | Integration | P0 | **Given** uv installed **When** uv sync **Then** dependencies resolved | Tool integration |

#### Enhanced uv Testing

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-INT-006 | Integration | P0 | **Given** conflicting deps **When** uv resolve **Then** deterministic solution | Dependency stability |
| 1.1-INT-007 | Integration | P1 | **Given** private registry **When** uv install **Then** auth works | Enterprise setup |
| 1.1-INT-008 | Integration | P1 | **Given** offline mode **When** uv sync --offline **Then** cached deps used | Resilience |
| 1.1-UNIT-005 | Unit | P1 | **Given** uv.lock **When** hash check **Then** integrity verified | Security |

### AC3: Black & Mypy Configured

#### Core Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-006 | Unit | P0 | **Given** Black config **When** line-length read **Then** equals 88 | Config validation |
| 1.1-UNIT-007 | Unit | P0 | **Given** Mypy config **When** strict mode **Then** all checks enabled | Type safety |
| 1.1-INT-009 | Integration | P0 | **Given** Python file **When** black format **Then** consistent style | Tool execution |
| 1.1-INT-010 | Integration | P0 | **Given** typed code **When** mypy check **Then** no errors | Type checking |

#### Architecture Validation Tests (Critical Focus Area)

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-008 | Unit | P0 | **Given** import statement **When** parse **Then** detect layer violation | Architecture rule |
| 1.1-UNIT-009 | Unit | P0 | **Given** domain module **When** analyze imports **Then** no adapter imports | Hexagonal integrity |
| 1.1-INT-011 | Integration | P0 | **Given** src/ structure **When** validate **Then** hexagonal layers present | Structure check |
| 1.1-INT-012 | Integration | P0 | **Given** adapter change **When** build **Then** domain unchanged | Dependency inversion |
| 1.1-E2E-002 | E2E | P0 | **Given** new feature **When** implement **Then** architecture boundaries maintained | Critical validation |

#### Advanced Architecture Tests

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-010 | Unit | P0 | **Given** application layer **When** import check **Then** only domain imports allowed | Layer purity |
| 1.1-UNIT-011 | Unit | P0 | **Given** adapter layer **When** dependency scan **Then** implements port interfaces | Port validation |
| 1.1-INT-013 | Integration | P1 | **Given** circular import attempt **When** import **Then** detection and error | Cycle prevention |
| 1.1-INT-014 | Integration | P1 | **Given** pre-commit hook **When** architecture violation **Then** commit blocked | Gate enforcement |

### AC4: README with uv Setup Instructions

#### Core Scenarios

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-012 | Unit | P1 | **Given** README **When** parse **Then** uv install command present | Doc validation |
| 1.1-E2E-003 | E2E | P0 | **Given** new developer **When** follow README **Then** environment ready < 30min | Onboarding test |

#### Linux Developer Onboarding Tests

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-E2E-002 | E2E | P0 | **Given** Linux developer **When** run onboard.py **Then** setup complete < 15min | Fast onboarding |
| 1.1-INT-004 | Integration | P0 | **Given** Linux setup script **When** execute **Then** all validations pass | Automated setup |
| 1.1-INT-005 | Integration | P1 | **Given** missing Linux package **When** setup **Then** apt install command shown | Help provided |
| 1.1-UNIT-004 | Unit | P1 | **Given** version check **When** Python < 3.13 **Then** installation guide shown | Version help |

#### Docker/Container Tests (Linux Deployment)

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-INT-006 | Integration | P0 | **Given** Dockerfile **When** build on Linux **Then** optimized layers | Container efficiency |
| 1.1-INT-007 | Integration | P0 | **Given** docker-compose **When** up **Then** all services healthy | Stack validation |
| 1.1-E2E-003 | E2E | P0 | **Given** production build **When** deploy **Then** < 100MB image size | Deployment ready |
| 1.1-UNIT-005 | Unit | P1 | **Given** Docker config **When** analyze **Then** security best practices | Secure by default |

### Linux-Specific Edge Cases

| ID | Level | Priority | Test | Justification |
|---|---|---|---|---|
| 1.1-UNIT-006 | Unit | P2 | **Given** low memory **When** check **Then** warn if < 2GB RAM | Resource validation |
| 1.1-INT-008 | Integration | P2 | **Given** firewall blocking **When** uv install **Then** proxy instructions | Network issues |
| 1.1-INT-009 | Integration | P2 | **Given** SELinux enabled **When** setup **Then** correct contexts set | Security compliance |

## Risk Coverage Matrix (Linux MVP)

| Risk ID | Mitigated By | Test Coverage |
|---|---|---|
| OPS-001 (Linux setup issues) | 1.1-E2E-001, 002, INT-002, 003 | 100% |
| TECH-003 (Architecture violations) | All UNIT-008 through UNIT-011, INT-010, 011 | 100% |
| OPS-003 (Container deployment) | 1.1-INT-006, 007, E2E-003 | 100% |
| SEC-001 (Security baseline) | 1.1-UNIT-005, INT-009 | 80% |

## Recommended Execution Order (Linux MVP)

### Phase 1: Core Linux Setup (Must Pass)
1. **Linux environment tests** - Verify Linux compatibility
2. **Python 3.13 & uv tests** - Core tooling
3. **Architecture validation** - Hexagonal boundaries

### Phase 2: Container Validation
4. **Docker build tests** - Image optimization
5. **Docker-compose tests** - Stack validation
6. **Production build test** - Deployment ready

### Phase 3: Developer Experience
7. **Onboarding automation** - < 15 minute setup
8. **Tool integration** - All dev tools working

### Phase 4: Edge Cases
9. **Resource constraints** - Low memory/disk
10. **Network issues** - Proxy/firewall

## Test Implementation Guidelines

### For Environment Consistency Tests
```python
# Example test structure
@pytest.mark.parametrize("platform", ["windows", "macos", "linux"])
def test_cross_platform_setup(platform, tmp_path):
    """Given different OS When setup Then consistent result"""
    # Mock platform-specific behavior
    # Execute setup
    # Assert identical outcomes
```

### For Architecture Validation Tests
```python
# Example boundary check
def test_hexagonal_boundaries():
    """Given domain module When analyzed Then no adapter imports"""
    from ast import parse, walk, Import, ImportFrom
    
    domain_files = Path("src/domain").glob("**/*.py")
    for file in domain_files:
        tree = parse(file.read_text())
        for node in walk(tree):
            if isinstance(node, (Import, ImportFrom)):
                assert "adapters" not in str(node.module)
```

### For Onboarding Verification
```bash
# Example onboarding test script
#!/bin/bash
# test_onboarding.sh

start_time=$(date +%s)

# Run setup
./setup.sh

# Verify all tools
uv --version || exit 1
black --version || exit 1
mypy --version || exit 1

end_time=$(date +%s)
duration=$((end_time - start_time))

# Assert under 30 minutes (1800 seconds)
[ $duration -lt 1800 ] || exit 1
```

## Quality Metrics

### Coverage Goals
- **Acceptance Criteria**: 100% covered
- **Risk Mitigation**: 100% high risks addressed
- **Platform Coverage**: Windows, macOS, Linux tested
- **Architecture Validation**: Automated from day one

### Test Efficiency
- **No duplicate coverage** across levels
- **Shift-left approach** - 79% unit/integration
- **Fast feedback** - P0 units run in <1 second
- **Maintainable** - Clear Given-When-Then format

## Special Considerations

### Python 3.13 & uv Experience
Since user has production experience with these tools:
- Focus tests on team knowledge transfer
- Emphasize documentation accuracy
- Test troubleshooting guides completeness

### Docker Strategy
- Provide BOTH native and Docker options
- Test that Docker matches native exactly
- Ensure volume mounts work correctly
- Validate hot reload functionality

### Architecture Enforcement
- Implement tests BEFORE code
- Use AST parsing for deep validation  
- Create visual dependency graphs
- Fail builds on violations

---
*Test Design Complete - Story 1.1*  
*42 comprehensive test scenarios designed*  
*Generated by Quinn (Test Architect)*